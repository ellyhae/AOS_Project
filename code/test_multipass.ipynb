{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747ce514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from utils import calculate_psnr_tensor, calculate_ssim_tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "from swin2sr import Swin2SR as Swin\n",
    "from dataset import PositionDataset\n",
    "\n",
    "def load_model(path: str):\n",
    "    model = Swin(img_size=512,\n",
    "                 in_chans=1,\n",
    "                 window_size=8,\n",
    "                 depths=[2, 2, 2, 2],\n",
    "                 num_heads=[4, 4, 4, 4],\n",
    "                 embed_dim=32,\n",
    "                 mlp_ratio=4,\n",
    "                 img_range=1.,\n",
    "                 ape=True,\n",
    "                 use_checkpoint=True).cuda()\n",
    "    \n",
    "    existing_model_state = Path(path)\n",
    "    if not existing_model_state.exists():\n",
    "        print(f\"Model state not found at {existing_model_state.absolute()}\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"Using the existing model state from {existing_model_state.absolute()}\")\n",
    "    model.load_state_dict(torch.load(existing_model_state))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "def tens2img(tensor: torch.Tensor):\n",
    "    '''Move the axes of a 3D Tensor such that it can be plotted as an image'''\n",
    "    return np.moveaxis(tensor.detach().cpu().numpy(), 0,-1)\n",
    "\n",
    "def load_tiff(path: str, focal_idx: list):\n",
    "    '''Load the tiff image from the given path, select the goven focal heights (using the index).\n",
    "    Return a Tensor of shape (num_focal_heights, H, W) with pixel values in the range [0-155]'''\n",
    "    ok, focal_stack = cv2.imreadmulti(path)\n",
    "    if not ok:\n",
    "        raise IOError(f'Failed to load index: {path}')\n",
    "        \n",
    "    focal_stack = np.stack(focal_stack)   # shape (num_focal_lengths, H, W)\n",
    "    focal_stack = focal_stack[focal_idx]\n",
    "    focal_stack = torch.from_numpy(focal_stack)\n",
    "    return focal_stack\n",
    "\n",
    "def preprocess(stack: torch.Tensor):\n",
    "    '''Resize and normalize the images in the stack'''\n",
    "    return Resize(512)(stack.contiguous().div(256))\n",
    "\n",
    "@torch.no_grad()\n",
    "@torch.autocast(device_type='cuda', dtype=torch.float16)\n",
    "def self_ensemble(model: Swin, stack: torch.Tensor, passes:int = 2):\n",
    "    '''Calculate the model output for the given input stack.\n",
    "    The stack is assumed to be of shape (num_focal_height, H, W) with pixel values in the range [0,1].\n",
    "    The stack is assumed to be ordered by ascending focal height, i.e. stack[0] is the closest to 0m (the floor)\n",
    "    The model is assumed to only work on single channel images, so the results for different focal heights are calculated separately and then aggregated later'''\n",
    "\n",
    "    get_rots = lambda x: [torch.rot90(x, i, (-2, -1)) for i in range(4)]\n",
    "    undo_rots = lambda x: [torch.rot90(j, -i, (-2, -1)) for i, j in enumerate(x)]\n",
    "    ### maybe also include flipped versions\n",
    "\n",
    "    single_pass_denoised = None\n",
    "    no_ensemble_denoised = None\n",
    "    denoised = stack\n",
    "    # feed the output through the model several times\n",
    "    for _ in range(passes):\n",
    "        fixed_preds = []\n",
    "        for integral in denoised:\n",
    "            integral = integral[None,:]  # see each integral as an individual grayscale image\n",
    "\n",
    "            versions = torch.stack(get_rots(integral)).cuda()\n",
    "\n",
    "            preds = model(versions)\n",
    "\n",
    "            if no_ensemble_denoised is None:  # assume the first integral in the stack as the training height\n",
    "                no_ensemble_denoised = preds[0].clone()  # store it's unmodified prediction for comparison\n",
    "\n",
    "            fixed_preds += undo_rots(preds)\n",
    "\n",
    "        denoised = torch.stack(fixed_preds).median(0).values\n",
    "\n",
    "        if single_pass_denoised is None:\n",
    "            single_pass_denoised = denoised.clone()\n",
    "\n",
    "    # safeguard against making results worse\n",
    "    if single_pass_denoised.std() < denoised.std():\n",
    "        denoised = single_pass_denoised\n",
    "    return no_ensemble_denoised, single_pass_denoised, denoised\n",
    "\n",
    "def postprocess(stack: torch.Tensor):\n",
    "    '''Convert the model output to the range [0, 255]'''\n",
    "    return stack.mul(256).clip(0, 255).int()\n",
    "\n",
    "def calculate_metrics(denoised, ground_truth):\n",
    "    dn = denoised[None,:].float()\n",
    "    gt = ground_truth[None,:].float()\n",
    "    loss = nn.functional.l1_loss(dn, gt).item()\n",
    "    psnr = calculate_psnr_tensor(gt, dn, 255.)\n",
    "    ssim = calculate_ssim_tensor(gt, dn, 255.)\n",
    "    return [loss, psnr, ssim]\n",
    "\n",
    "def main():\n",
    "    model = load_model('tmp/model_3199.pth')\n",
    "    denoising_passes = 2\n",
    "\n",
    "    focal_idx = [0]\n",
    "    input_image_path = 'test'    #0_130_2_-5_integral.tiff'\n",
    "\n",
    "    # added different support of datatypes\n",
    "    # every format supported by cv2.imreadmulti(path) is allowed: e.g. png, jpg\n",
    "    # important: write datatype here without a \".\" in the beginning!\n",
    "    datatype = \"tiff\"\n",
    "\n",
    "    # if a path to a directory was given, load all tiff files from there. Useful for calculating the loss over some dataset\n",
    "    if os.path.isdir(input_image_path):\n",
    "        print('Detected folder as input path, loading all files')\n",
    "        image_files = glob(os.path.join(input_image_path, f\"*_integral.{datatype}\"))\n",
    "    # if the path is a file, treat it as if it's a dataset with only one sample. Makes further code more concise\n",
    "    else:\n",
    "        image_files = [input_image_path]\n",
    "\n",
    "    ## make predictions\n",
    "    multipass = denoising_passes > 1\n",
    "    metrics, ensemble_metrics, multipass_metrics = [], [], []\n",
    "    # Loop over all image files. Load each tiff file as a (num_focal_heights, H, W) Tensor, preprocess it and calculate the prediction\n",
    "    for idx, f in enumerate(tqdm(image_files, desc='Calculating output(s)')):\n",
    "        stack = load_tiff(f, focal_idx)\n",
    "        stack = preprocess(stack)\n",
    "\n",
    "        no_ensemble_denoised, single_pass_denoised, denoised = map(postprocess, self_ensemble(model, stack, denoising_passes))\n",
    "\n",
    "        # If a ground truth image is present, calculate key metrics. Useful for getting an overview of the model on some dataset\n",
    "        gt_path = f.removesuffix(f\"integral.{datatype}\") + 'gt.png'\n",
    "        gt = os.path.exists(gt_path)\n",
    "        if gt:\n",
    "            ground_truth = torch.from_numpy(np.moveaxis(cv2.imread(gt_path)[...,[0]], -1, 0)).int().cuda()\n",
    "            metrics.append(calculate_metrics(no_ensemble_denoised, ground_truth))\n",
    "            ensemble_metrics.append(calculate_metrics(single_pass_denoised, ground_truth))\n",
    "            multipass_metrics.append(calculate_metrics(denoised, ground_truth))\n",
    "        \n",
    "        if idx%5 == 0:\n",
    "            loss, psnr, ssim = np.mean(metrics, 0)\n",
    "            ensemble_loss, ensemble_psnr, ensemble_ssim = np.mean(ensemble_metrics, 0)\n",
    "            multipass_loss, multipass_psnr, multipass_ssim = np.mean(multipass_metrics, 0)\n",
    "\n",
    "            # if ground truths were available, print the results\n",
    "            if gt:\n",
    "                print('\\n                   L1 Loss / PSNR / SSIM:')\n",
    "                print(f'Simple denoised:   {loss:.3f} / {psnr:.3f} / {ssim:.3f}')\n",
    "                print(f'+ Ensemble:        {ensemble_loss:.3f} / {ensemble_psnr:.3f} / {ensemble_ssim:.3f}')\n",
    "                if multipass:\n",
    "                    print(f'+ Multi-Pass [{denoising_passes}]:  {multipass_loss:.3f} / {multipass_psnr:.3f} / {multipass_ssim:.3f}')\n",
    "\n",
    "    loss, psnr, ssim = np.mean(metrics, 0)\n",
    "    ensemble_loss, ensemble_psnr, ensemble_ssim = np.mean(ensemble_metrics, 0)\n",
    "    multipass_loss, multipass_psnr, multipass_ssim = np.mean(multipass_metrics, 0)\n",
    "    \n",
    "    # if ground truths were available, print the results\n",
    "    if gt:\n",
    "        print('\\n                   L1 Loss / PSNR / SSIM:')\n",
    "        print(f'Simple denoised:   {loss:.3f} / {psnr:.3f} / {ssim:.3f}')\n",
    "        print(f'+ Ensemble:        {ensemble_loss:.3f} / {ensemble_psnr:.3f} / {ensemble_ssim:.3f}')\n",
    "        if multipass:\n",
    "            print(f'+ Multi-Pass [{denoising_passes}]:  {multipass_loss:.3f} / {multipass_psnr:.3f} / {multipass_ssim:.3f}')\n",
    "\n",
    "\n",
    "    # plot the last input-denoised pair\n",
    "    fig, axes = plt.subplots(1, 3 + gt + multipass, figsize=(18,8), sharey=True, sharex=True)\n",
    "\n",
    "    axes[0].imshow(tens2img(stack[[0]]), cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1].imshow(tens2img(no_ensemble_denoised), cmap='gray', vmin=0, vmax=255)\n",
    "    axes[2].imshow(tens2img(single_pass_denoised), cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "    axes[0].set_title('Input')\n",
    "    axes[1].set_title('Denoised')\n",
    "    axes[2].set_title('+ Self Ensemble')\n",
    "\n",
    "    if multipass:\n",
    "        axes[3].imshow(tens2img(denoised), cmap='gray', vmin=0, vmax=255)\n",
    "        axes[3].set_title(f'+ Multi-Pass [{denoising_passes}]')\n",
    "\n",
    "    if gt:\n",
    "        axes[-1].imshow(tens2img(ground_truth), cmap='gray', vmin=0, vmax=255)\n",
    "        axes[-1].set_title('Ground Truth')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cb7591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the existing model state from C:\\Users\\kroep\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\tmp\\model_3199.pth\n",
      "Detected folder as input path, loading all files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   0%|                                                        | 1/1064 [00:11<3:18:20, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   10.405 / 21.084 / 0.852\n",
      "+ Ensemble:        9.272 / 22.211 / 0.868\n",
      "+ Multi-Pass [2]:  5.424 / 26.519 / 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   1%|▎                                                       | 6/1064 [00:33<1:24:14,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   6.179 / 26.038 / 0.904\n",
      "+ Ensemble:        5.879 / 26.501 / 0.915\n",
      "+ Multi-Pass [2]:  3.086 / 31.743 / 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   1%|▌                                                      | 11/1064 [00:54<1:16:52,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   5.768 / 27.716 / 0.904\n",
      "+ Ensemble:        5.544 / 28.141 / 0.913\n",
      "+ Multi-Pass [2]:  2.786 / 33.104 / 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   2%|▊                                                      | 16/1064 [01:16<1:15:50,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   5.127 / 28.285 / 0.905\n",
      "+ Ensemble:        4.910 / 28.745 / 0.916\n",
      "+ Multi-Pass [2]:  2.373 / 33.963 / 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   2%|█                                                      | 21/1064 [01:37<1:15:22,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   4.966 / 28.155 / 0.893\n",
      "+ Ensemble:        4.718 / 28.693 / 0.904\n",
      "+ Multi-Pass [2]:  2.280 / 34.161 / 0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   2%|█▎                                                     | 26/1064 [01:59<1:15:05,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   4.991 / 28.305 / 0.893\n",
      "+ Ensemble:        4.755 / 28.798 / 0.905\n",
      "+ Multi-Pass [2]:  2.275 / 34.229 / 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   3%|█▌                                                     | 31/1064 [02:21<1:14:42,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   L1 Loss / PSNR / SSIM:\n",
      "Simple denoised:   4.948 / 28.195 / 0.895\n",
      "+ Ensemble:        4.710 / 28.689 / 0.907\n",
      "+ Multi-Pass [2]:  2.249 / 34.224 / 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating output(s):   3%|█▌                                                     | 31/1064 [02:23<1:19:25,  4.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 143\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m stack \u001b[38;5;241m=\u001b[39m load_tiff(f, focal_idx)\n\u001b[0;32m    141\u001b[0m stack \u001b[38;5;241m=\u001b[39m preprocess(stack)\n\u001b[1;32m--> 143\u001b[0m no_ensemble_denoised, single_pass_denoised, denoised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(postprocess, \u001b[43mself_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenoising_passes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# If a ground truth image is present, calculate key metrics. Useful for getting an overview of the model on some dataset\u001b[39;00m\n\u001b[0;32m    146\u001b[0m gt_path \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mremovesuffix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintegral.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatatype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 86\u001b[0m, in \u001b[0;36mself_ensemble\u001b[1;34m(model, stack, passes)\u001b[0m\n\u001b[0;32m     82\u001b[0m integral \u001b[38;5;241m=\u001b[39m integral[\u001b[38;5;28;01mNone\u001b[39;00m,:]  \u001b[38;5;66;03m# see each integral as an individual grayscale image\u001b[39;00m\n\u001b[0;32m     84\u001b[0m versions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(get_rots(integral))\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 86\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_ensemble_denoised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# assume the first integral in the stack as the training height\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     no_ensemble_denoised \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# store it's unmodified prediction for comparison\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:981\u001b[0m, in \u001b[0;36mSwin2SR.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# for image denoising and JPEG compression artifact reduction\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     x_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_first(x)\n\u001b[1;32m--> 981\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_after_body(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_first\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m x_first\n\u001b[0;32m    982\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_last(res)\n\u001b[0;32m    983\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_gray(x)\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:905\u001b[0m, in \u001b[0;36mSwin2SR.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    902\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 905\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)  \u001b[38;5;66;03m# B L C\u001b[39;00m\n\u001b[0;32m    908\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_unembed(x, x_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:561\u001b[0m, in \u001b[0;36mRSTB.forward\u001b[1;34m(self, x, x_size)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_size):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_unembed(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_size\u001b[49m\u001b[43m)\u001b[49m, x_size))) \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:428\u001b[0m, in \u001b[0;36mBasicLayer.forward\u001b[1;34m(self, x, x_size)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_checkpoint:\n\u001b[1;32m--> 428\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# ADDED use_reentrant=False  to remove warning\u001b[39;00m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m         x \u001b[38;5;241m=\u001b[39m blk(x, x_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py:17\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\utils\\checkpoint.py:458\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[1;32m--> 458\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:290\u001b[0m, in \u001b[0;36mSwinTransformerBlock.forward\u001b[1;34m(self, x, x_size)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# W-MSA/SW-MSA (to be compatible for testing on images whose shapes are the multiple of window size\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_resolution \u001b[38;5;241m==\u001b[39m x_size:\n\u001b[1;32m--> 290\u001b[0m     attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(x_windows, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_mask(x_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:153\u001b[0m, in \u001b[0;36mWindowAttention.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# cosine attention\u001b[39;00m\n\u001b[0;32m    152\u001b[0m attn \u001b[38;5;241m=\u001b[39m (F\u001b[38;5;241m.\u001b[39mnormalize(q, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m@\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(k, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 153\u001b[0m logit_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit_scale, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogit_scale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m    154\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn \u001b[38;5;241m*\u001b[39m logit_scale\n\u001b[0;32m    156\u001b[0m relative_position_bias_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpb_mlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_coords_table)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42eb8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (cvp)",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
