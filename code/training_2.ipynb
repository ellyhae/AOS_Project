{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "281a03ad",
   "metadata": {},
   "source": [
    "# Training with second pass through the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8dfd3",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "- Specify the path to the train folder and its name. This info is saved in the train_path variable.\n",
    "- Specify the path to the val folder and its name. This info is saved in the  train_path variable.\n",
    "- Specify the path to the model. This info is saved in the load_model_path variable.\n",
    "- Create a folder called tmp, where the best model and other training realated stuff will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_every = 200  # e.g. run validation set, save model, print some logs every n updates  /  keep pretty high, validation \"wastes\" time, but also not too high, as the lr_scheduler needs the result as input to do anything\n",
    "samples_per_update = 16\n",
    "train_path = 'train2'\n",
    "val_path = 'val'\n",
    "load_model_path = 'tmp/model_190k.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0859ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from validate_2 import validate_dataset\n",
    "from utils import end_timer_and_print, start_timer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from swin2sr import Swin2SR as Swin\n",
    "from dataset import PositionDataset\n",
    "from loss import PositionEnhancedLoss\n",
    "from tqdm import trange\n",
    "\n",
    "import os\n",
    "\n",
    "# from https://github.com/styler00dollar/pytorch-loss-functions/blob/main/vic/loss.py#L27\n",
    "class CharbonnierLoss(nn.Module):\n",
    "    \"\"\"Charbonnier Loss (L1)\"\"\"\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super(CharbonnierLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        b, c, h, w = y.size()\n",
    "        loss = torch.sum(torch.sqrt((x - y).pow(2) + self.eps**2))\n",
    "        return loss/(c*b*h*w)\n",
    "\n",
    "def get_batch(data_iterator, train_dl):\n",
    "    '''convenience function to infinitely sample from the dataset'''\n",
    "    res = next(data_iterator, None)\n",
    "    if res is None:\n",
    "        data_iterator = iter(train_dl)\n",
    "        res = next(data_iterator)\n",
    "    stack, gt, pos = res\n",
    "    return data_iterator, stack.cuda(non_blocking=True), gt.cuda(non_blocking=True), pos.cuda(non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd99015",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 1/10000 [01:55<321:56:51, 115.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 2 Training Loss: 0.0189 Validation Loss/PSNR/SSIM: 0.0151 29.9588 0.9361\n",
      "Best validation loss found -> saving the model to C:\\Users\\kroep\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\tmp\\model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/10000 [06:04<324:57:25, 117.02s/it, train_loss=0.0189, val_loss=0.0151, val_psnr=30, val_ssim=0.936]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 4 Training Loss: 0.0185 Validation Loss/PSNR/SSIM: 0.0168 29.0450 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/10000 [10:31<339:14:04, 122.19s/it, train_loss=0.0185, val_loss=0.0168, val_psnr=29, val_ssim=0.933]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 6 Training Loss: 0.0365 Validation Loss/PSNR/SSIM: 0.0147 29.6577 0.9271\n",
      "Best validation loss found -> saving the model to C:\\Users\\kroep\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\tmp\\model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|        | 7/10000 [14:53<338:19:04, 121.88s/it, train_loss=0.0365, val_loss=0.0147, val_psnr=29.7, val_ssim=0.927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 8 Training Loss: 0.0283 Validation Loss/PSNR/SSIM: 0.0139 29.8412 0.9379\n",
      "Best validation loss found -> saving the model to C:\\Users\\kroep\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\tmp\\model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|        | 9/10000 [21:35<399:30:54, 143.95s/it, train_loss=0.0283, val_loss=0.0139, val_psnr=29.8, val_ssim=0.938]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(temp_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m\u001b[38;5;241m*\u001b[39maccumulate_batches:]))\n\u001b[0;32m    123\u001b[0m temp_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 125\u001b[0m val_loss, val_psnr, val_ssim, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mlast_batch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Validation Loss/PSNR/SSIM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_psnr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_ssim\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\validate_2.py:39\u001b[0m, in \u001b[0;36mvalidate_dataset\u001b[1;34m(validation_dl, model, loss_fn, double_pass)\u001b[0m\n\u001b[0;32m     36\u001b[0m gt \u001b[38;5;241m=\u001b[39m gt\u001b[38;5;241m.\u001b[39mcuda(non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[1;32m---> 39\u001b[0m     denoised \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# feed the input to the network\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m double_pass:\n\u001b[0;32m     42\u001b[0m         denoised \u001b[38;5;241m=\u001b[39m model(denoised)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:981\u001b[0m, in \u001b[0;36mSwin2SR.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# for image denoising and JPEG compression artifact reduction\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     x_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_first(x)\n\u001b[1;32m--> 981\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_after_body(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_first\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m+\u001b[39m x_first\n\u001b[0;32m    982\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_last(res)\n\u001b[0;32m    983\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_gray(x)\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:905\u001b[0m, in \u001b[0;36mSwin2SR.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    902\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 905\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)  \u001b[38;5;66;03m# B L C\u001b[39;00m\n\u001b[0;32m    908\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_unembed(x, x_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:561\u001b[0m, in \u001b[0;36mRSTB.forward\u001b[1;34m(self, x, x_size)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_size):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_unembed(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_size\u001b[49m\u001b[43m)\u001b[49m, x_size))) \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:428\u001b[0m, in \u001b[0;36mBasicLayer.forward\u001b[1;34m(self, x, x_size)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_checkpoint:\n\u001b[1;32m--> 428\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# ADDED use_reentrant=False  to remove warning\u001b[39;00m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m         x \u001b[38;5;241m=\u001b[39m blk(x, x_size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:328\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py:17\u001b[0m, in \u001b[0;36mwrap_inline.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\utils\\checkpoint.py:458\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[1;32m--> 458\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:290\u001b[0m, in \u001b[0;36mSwinTransformerBlock.forward\u001b[1;34m(self, x, x_size)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# W-MSA/SW-MSA (to be compatible for testing on images whose shapes are the multiple of window size\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_resolution \u001b[38;5;241m==\u001b[39m x_size:\n\u001b[1;32m--> 290\u001b[0m     attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(x_windows, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_mask(x_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cvp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\AI\\computer_vision\\AOS_Project-main-2024-01-17\\AOS_Project-main\\code\\swin2sr.py:153\u001b[0m, in \u001b[0;36mWindowAttention.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# cosine attention\u001b[39;00m\n\u001b[0;32m    152\u001b[0m attn \u001b[38;5;241m=\u001b[39m (F\u001b[38;5;241m.\u001b[39mnormalize(q, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m@\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(k, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 153\u001b[0m logit_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit_scale, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogit_scale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m    154\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn \u001b[38;5;241m*\u001b[39m logit_scale\n\u001b[0;32m    156\u001b[0m relative_position_bias_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpb_mlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_coords_table)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.manual_seed(43)\n",
    "np.random.seed(43)\n",
    "\n",
    "focal_idx = [0]\n",
    "train_ds = PositionDataset(path=train_path, used_focal_lengths_idx=focal_idx, augment=True)\n",
    "\n",
    "batch_size = 2\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,     # only for training set!\n",
    "                      num_workers=4,    # could be useful to prefetch data while the GPU is working\n",
    "                      pin_memory=True)  # should speed up CPU to GPU data transfer\n",
    "ds_iter, stack, gt, pos = get_batch(iter(train_dl), train_dl)\n",
    "\n",
    "val_ds = PositionDataset(path=val_path, used_focal_lengths_idx=focal_idx, augment=False)\n",
    "val_dl = DataLoader(val_ds,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False,     # only for training set!\n",
    "                    num_workers=4,    # could be useful to prefetch data while the GPU is working\n",
    "                    pin_memory=True)  # should speed up CPU to GPU data transfer\n",
    "\n",
    "\n",
    "################ Mostly change parameters here (plus the dataset paths above) ##################\n",
    "\n",
    "load_last = False    # True: resume training, False: start new training and overwrite old files\n",
    "num_updates = 5000          # the number of gradient updates we want to do (would advise this to be a multiple of checkpoint_every)\n",
    "accumulate_batches = samples_per_update // batch_size    # the number of batches we need to compute to do a single gradient update\n",
    "num_batches = num_updates * accumulate_batches           # the number of batches we need to reach our goal of updates and samples_per_update\n",
    "\n",
    "model = Swin(img_size=512,\n",
    "             in_chans=len(focal_idx),\n",
    "             window_size=8,\n",
    "             depths=[2, 2, 2, 2],\n",
    "             num_heads=[4, 4, 4, 4],\n",
    "             embed_dim=32,\n",
    "             mlp_ratio=4,\n",
    "             img_range=1.,\n",
    "             ape=True,\n",
    "             use_checkpoint=True).cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(load_model_path))\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "loss_fn = PositionEnhancedLoss(length=96, factor=.5).cuda()\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()  # used to scale the loss/gradients to prevent float underflow\n",
    "\n",
    "temp_losses = []\n",
    "train_losses = []\n",
    "best_val_loss = None\n",
    "stats = dict()\n",
    "\n",
    "model_path = Path('tmp/model.pth')\n",
    "model_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "last_batch_num = 0\n",
    "\n",
    "\n",
    "if load_last:\n",
    "    model.load_state_dict(torch.load('tmp/model.pth'))\n",
    "    optimizer.load_state_dict(torch.load('tmp/last_optimizer.pth'))\n",
    "    lr_scheduler.load_state_dict(torch.load('tmp/last_scheduler.pth'))\n",
    "    scaler.load_state_dict(torch.load('tmp/last_scaler.pth'))\n",
    "    for group, lr in zip(optimizer.param_groups, lr_scheduler._last_lr):\n",
    "        print('Using last Learning Rate:', lr)\n",
    "        group['lr'] = lr\n",
    "\n",
    "    stats: dict = json.loads(Path('tmp/stats.json').read_text())\n",
    "    last_batch_num = max(map(int, stats.keys()))\n",
    "    train_losses, val_losses, _, _ = zip(*stats.values())\n",
    "    train_losses = list(train_losses)\n",
    "    print('Last training losses',train_losses)\n",
    "    best_val_loss = min(val_losses)\n",
    "    print('Best val loss:', best_val_loss)\n",
    "    del val_losses\n",
    "\n",
    "start_timer()\n",
    "\n",
    "loop = trange(num_batches)\n",
    "\n",
    "switch_val = -1\n",
    "save_idx = 0\n",
    "\n",
    "for batch_count in loop:\n",
    "    \n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "        \n",
    "        denoised = model(stack)   # feed the input to the network\n",
    "        denoised_2 = model(denoised)   # feed the output of the model to itself\n",
    "        \n",
    "        if switch_val == 1:\n",
    "            loss = loss_fn(denoised, gt, pos)\n",
    "        else:\n",
    "            loss = loss_fn(denoised_2, gt, pos)\n",
    "        \n",
    "        acc_loss = loss / accumulate_batches\n",
    "        scaler.scale(acc_loss).backward(retain_graph=True)  # scale loss and calculate gradients\n",
    "        \n",
    "        switch_val *= -1  # flip the switch\n",
    "    \n",
    "    ds_iter, stack, gt, pos = get_batch(ds_iter, train_dl)  # load batch during logging and back-propagation\n",
    "    \n",
    "    temp_losses.append(loss.item())\n",
    "    \n",
    "    scaler.scale(acc_loss).backward()  # scale loss and calculate gradients\n",
    "    \n",
    "    if (batch_count + 1) % accumulate_batches == 0:\n",
    "        scaler.step(optimizer)         # update the weights\n",
    "        scaler.update()                # update scaling parameters\n",
    "        optimizer.zero_grad()          # reset gradients\n",
    "\n",
    "        if ((batch_count + 1) // accumulate_batches) % checkpoint_every == 0:\n",
    "            # every n-th update\n",
    "            train_losses.append(np.mean(temp_losses[-20*accumulate_batches:]))\n",
    "            temp_losses = []\n",
    "            \n",
    "            val_loss, val_psnr, val_ssim, _, _, _ = validate_dataset(val_dl, model, loss_fn, double_pass=True)\n",
    "            model.train()\n",
    "\n",
    "            print(f'\\nBatch {batch_count+1+last_batch_num} Training Loss: {train_losses[-1]:.4f} Validation Loss/PSNR/SSIM: {val_loss:.4f} {val_psnr:.4f} {val_ssim:.4f}')\n",
    "            stats[batch_count + 1+last_batch_num] = [train_losses[-1], val_loss, val_psnr, val_ssim]\n",
    "            Path('tmp/stats.json').write_text(json.dumps(stats))\n",
    "            \n",
    "            if best_val_loss == None or val_loss <= best_val_loss:\n",
    "                print(f'Best validation loss found -> saving the model to {model_path.absolute()}')\n",
    "                best_val_loss = val_loss\n",
    "            \n",
    "            torch.save(model.state_dict(), os.path.join('tmp', f'model_{save_idx}.pth'))\n",
    "\n",
    "            lr_scheduler.step(val_loss)\n",
    "            loop.set_postfix(dict(train_loss=train_losses[-1], val_loss=val_loss, val_psnr=val_psnr, val_ssim=val_ssim))\n",
    "        \n",
    "        save_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tmp/last_model.pth')\n",
    "torch.save(optimizer.state_dict(), 'tmp/last_optimizer.pth')\n",
    "torch.save(lr_scheduler.state_dict(), 'tmp/last_scheduler.pth')\n",
    "torch.save(scaler.state_dict(), 'tmp/last_scaler.pth')\n",
    "\n",
    "end_timer_and_print(f\"Finished training for {num_batches} batches with batch size {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08885c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (cvp)",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
